{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "from datetime import date\n",
    "import subprocess\n",
    "import sys  \n",
    "import operator\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "import math\n",
    "from itertools import combinations\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "favCutoff = \"40\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "import seaborn as sns\n",
    "\n",
    "import ete3\n",
    "from ete3 import NCBITaxa\n",
    "ncbi = NCBITaxa()\n",
    "\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Bio import SeqIO, Entrez\n",
    "Entrez.email = \"parsonsc@mit.edu\"\n",
    "Entrez.api_key = \"7a3fcee8ce251bc6a20619259badbd6f0e09\"\n",
    "\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#!{sys.executable} -m pip install --user biopython\n",
    "#!{sys.executable} -m pip install --user ete3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAlignmentOld(clusterName, seqIDs):\n",
    "    completed = subprocess.run([\"mkdir\", \"fullTrees/\"])\n",
    "    completed = subprocess.run([\"mkdir\", \"fullTrees/cluster\" + favCutoff])\n",
    "    if len(clusterName.split(\"_\")) > 2:\n",
    "        clusterName = \"_\".join(clusterName.split(\"_\")[:2])\n",
    "    alignment_name = clusterName + \".fasta\"\n",
    "    if filename in os.listdir(\"fullTrees/cluster\" + favCutoff):\n",
    "        print(\"File already found! (%s)\"%(filename))\n",
    "        raise Exception\n",
    "    \n",
    "    count = len(seqIDs)\n",
    "    out = open(\"fullTrees/cluster\" + favCutoff + \"/\" + filename, 'w')\n",
    "    batch_size = 500\n",
    "    for start in range(0, count, batch_size):\n",
    "        end = min(count, start+batch_size)\n",
    "        ids = ','.join(seqIDs[start:end])\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=\"protein\", rettype=\"fasta\", retmode=\"text\", id=ids)\n",
    "            out.write(handle.read())\n",
    "        except:\n",
    "            continue\n",
    "        handle.close()\n",
    "    out.close()\n",
    "    \n",
    "    print(count, \"sequences downloaded.\")\n",
    "    \n",
    "    name = \"mafft_\" + date.today().strftime(\"%m_%d_%Y\") + \"_\" + clusterName\n",
    "    commands = [\"module add engaging/mafft\",\n",
    "                \"mafft --localpair --maxiterate 1000 fullTrees/cluster\" + favCutoff + \n",
    "                \"/\" + filename + \" > alignments/cluster\" + favCutoff + \"/\" + clusterName + \".afa\"]\n",
    "    mafftSh = makeShell(name, commands, mem = '10')\n",
    "    print(mafftSh)\n",
    "\n",
    "    completed = subprocess.run([\"sbatch\",  \"--wait\",  mafftSh])\n",
    "    \n",
    "def makeFullTree(clusterName):\n",
    "    alignmentName = \"fullTrees/cluster\" + favCutoff + \"/\" + clusterName + \".afa\"\n",
    "    name = \"iqtree_\" + date.today().strftime(\"%m_%d_%Y\") + \"_\" + clusterName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastaToDictionary(alignmentName):\n",
    "    alignFile = open(alignmentName)\n",
    "    alines = alignFile.readlines()\n",
    "    alignFile.close\n",
    "\n",
    "    seqDict = {}\n",
    "    cur = \"\"\n",
    "\n",
    "    for line in alines:\n",
    "        l = line.strip()\n",
    "        if l == '':\n",
    "            continue\n",
    "        if l[0] == '>':\n",
    "            cur = l[1:]\n",
    "            seqDict[cur] = \"\"\n",
    "        else:\n",
    "            if cur not in seqDict:\n",
    "                print(alignmentName, l)\n",
    "            seqDict[cur] += l\n",
    "\n",
    "    return seqDict\n",
    "\n",
    "def makeShell(name, commands, nodes='1', cores='1', mem='10', days='7', max_queue='20', out=None):\n",
    "    if out == None:\n",
    "        out = name\n",
    "    if max_queue:\n",
    "        subprocess.call([\"while [ $( squeue -u parsonsc | wc -l) -gt \" + max_queue + \" ]; do\\n    sleep 10; done;\"], shell=True)\n",
    "    file = open(name + '.sh', 'w')\n",
    "    file.write( \"#!/bin/bash\\n\\n\"\n",
    "                \"#SBATCH -p sched_mit_g4nier\\n\"                                                                          \n",
    "                \"#SBATCH -t \" + days + \"-00:00:00\\n\"\n",
    "                \"#SBATCH -N \" + nodes + \"\\n\"\n",
    "                \"#SBATCH -n \" + cores + \"\\n\"\n",
    "                \"#SBATCH --mem=\" + mem + \"G\\n\"\n",
    "                \"#SBATCH -J \" + name + \"\\n\"\n",
    "                \"#SBATCH -o \" + out + \".out\\n\" +\n",
    "                '\\n'.join(commands))\n",
    "    file.close()\n",
    "    return name + '.sh'\n",
    "\n",
    "def removeRedundancy(fileName):\n",
    "    lines = [x.strip() for x in open(fileName).readlines()]\n",
    "    \n",
    "    seqDict = {}\n",
    "    \n",
    "    cur = ''\n",
    "    running = ''\n",
    "    for line in lines:\n",
    "        if line[0] == '>':\n",
    "            if cur != '':\n",
    "                if running not in seqDict.values():\n",
    "                    seqDict[cur] = running\n",
    "            cur = line[1:]\n",
    "            running = ''\n",
    "        else:\n",
    "            running += line\n",
    "    if running not in seqDict.values():\n",
    "        seqDict[cur] = running\n",
    "    \n",
    "    out = open(filename, 'w')\n",
    "    for seq in seqDict:\n",
    "        out.write(seq + '\\n' + seqDict[seq] + '\\n')\n",
    "    out.close()\n",
    "        \n",
    "def getSis(node):\n",
    "    if node.is_root():\n",
    "        return False\n",
    "    else:\n",
    "        return [x for x in node.up.children if x != node][0]\n",
    "    \n",
    "def getClade(node):\n",
    "    leaves = node.get_leaves()\n",
    "    oneEx = leaves[0].name[0]\n",
    "    if all(x.name[0] == oneEx for x in leaves):\n",
    "        return oneEx\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "# MAD file generated with -tf flag\n",
    "def addMADtoTree(treeFile, rootedTreeFile):\n",
    "    f = open(treeFile)\n",
    "    treeLine = f.readlines()[0]\n",
    "    f.close()\n",
    "    rf = open(rootedTreeFile)\n",
    "    rTreeLine = rf.readlines()[2][19:].replace(\",ADS=\", \"comADS=\").replace(\",STT=\", \"comSTT=\").split(\"[&ADS=\\\"AI\")[0] + \";\"\n",
    "    rf.close()\n",
    "\n",
    "    tree = ete3.Tree(treeLine, format=1)\n",
    "    rTree = ete3.Tree(rTreeLine, format=1)\n",
    "    if len(rTree.children[0]) == 1:\n",
    "        rTree = rTree.children[1]\n",
    "    else:\n",
    "        rTree = rTree.children[0]\n",
    "    rTreeOg = rTree.children[0]\n",
    "    if len(rTreeOg) == 1:\n",
    "        rTreeOg = rTree.children[1]\n",
    "    for leaf in rTree.get_leaves():\n",
    "        leaf.add_feature(\"label\", \"[\" + leaf.name.split(\"[\")[1])\n",
    "        leaf.name = leaf.name.split(\"[\")[0]\n",
    "    ogNames = [x.name for x in rTreeOg.get_leaves()]\n",
    "    for leaf in tree.get_leaves():\n",
    "        if leaf.name not in ogNames:\n",
    "            tree.set_outgroup(leaf)\n",
    "            break\n",
    "    treeOg = tree.get_common_ancestor(ogNames)\n",
    "    \n",
    "    tree.set_outgroup(treeOg)\n",
    "    treeNodes = list(tree.traverse())\n",
    "    rTreeNodes = list(rTree.traverse())\n",
    "    \n",
    "    for node in tree.traverse():\n",
    "        leafNames = [x.name for x in node.get_leaves()]\n",
    "        if len(node) == 1:\n",
    "            rNode = rTree&leafNames[0]\n",
    "            adVal = rNode.label.split(\"com\")[0].split(\"=\")[-1]\n",
    "            adsVal = rNode.label.split(\"com\")[1].split(\"=\")[-1]\n",
    "        else:\n",
    "            rNode = rTree.get_common_ancestor(leafNames)\n",
    "            adVal = rNode.name.split(\"com\")[0].split(\"=\")[-1]\n",
    "            adsVal = rNode.name.split(\"com\")[1].split(\"=\")[-1]\n",
    "        if len(rNode) != len(node):\n",
    "            print(\"Something wrong lol\", len(rNode), len(node))\n",
    "        node.add_features(AD=adVal, ADS=adsVal)\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeAlignment(clusterName, seqIDs, max_queue=\"20\"):\n",
    "    completed = subprocess.run([\"mkdir\", \"fullTrees/\"])\n",
    "    completed = subprocess.run([\"mkdir\", \"fullTrees/cluster\" + favCutoff])\n",
    "    completed = subprocess.run([\"mkdir\", \"fullTrees/cluster\" + favCutoff + \"/alignments\"])\n",
    "\n",
    "    filename = clusterName + \".fasta\"\n",
    "    if filename in os.listdir(\"fullTrees/cluster\" + favCutoff):\n",
    "        print(\"Fasta found! (%s)\"%(filename))\n",
    "    else:\n",
    "        count = len(seqIDs)\n",
    "        out = open(\"fullTrees/cluster\" + favCutoff + \"/\" + filename, 'w')\n",
    "        batch_size = 500\n",
    "        for start in range(0, count, batch_size):\n",
    "            end = min(count, start+batch_size)\n",
    "            ids = ','.join(seqIDs[start:end])\n",
    "            try:\n",
    "                handle = Entrez.efetch(db=\"protein\", rettype=\"fasta\", retmode=\"text\", id=ids)\n",
    "                out.write(handle.read())\n",
    "            except:\n",
    "                continue\n",
    "            handle.close()\n",
    "        out.close()\n",
    "    \n",
    "    #print(count, \"sequences downloaded.\")\n",
    "    \n",
    "    if filename[:-5] + \"afa\" in os.listdir(\"fullTrees/cluster\" + favCutoff + \"/alignments/\"):\n",
    "        print(\"Alignment already found! (%s)\"%(filename[:-5] + \"afa\"))\n",
    "    else:\n",
    "        name = \"mafft_\" + date.today().strftime(\"%m_%d_%Y\") + \"_\" + clusterName\n",
    "        commands = [\"module add engaging/mafft\",\n",
    "                    \"mafft --retree 2 --maxiterate 1000 fullTrees/cluster\" + favCutoff + \n",
    "                    \"/\" + filename + \" > fullTrees/cluster\" + favCutoff + \"/alignments/\" + filename[:-5] + \"afa\"]\n",
    "        mafftSh = makeShell(name, commands, mem = '10', max_queue=max_queue)\n",
    "        #print(mafftSh)\n",
    "        completed = subprocess.run([\"sbatch\", mafftSh])\n",
    "        #completed = subprocess.run([\"sbatch\",  \"--wait\",  mafftSh])\n",
    "    \n",
    "def makeFullTree(clusterName):\n",
    "    alignmentName = \"fullTrees/cluster\" + favCutoff + \"/\" + clusterName + \".afa\"\n",
    "    name = \"iqtree_\" + date.today().strftime(\"%m_%d_%Y\") + \"_\" + clusterName\n",
    "\n",
    "\n",
    "def generate_small_alignments(cluster, blast_path, n=10, batch_size=300, \n",
    "                              full_tree=False, skip_duplicates=False, return_tax=False):\n",
    "    seq_ids = {}\n",
    "    seq_tax = {}\n",
    "    with open(blast_path) as f:\n",
    "        prev_tid = None\n",
    "        for line in f:\n",
    "            parts = [x.strip() for x in line.split()]\n",
    "            if cluster in parts[1].split(\",\"):\n",
    "                if skip_duplicates and (parts[2] == prev_tid):\n",
    "                    continue\n",
    "                else:\n",
    "                    prev_tid = parts[2]\n",
    "                    seq_ids[parts[0]] = parts[3]\n",
    "                    seq_tax[parts[0]] = parts[2]\n",
    "    #met = [x for x in seq_ids if seq_ids[x]==\"m\"]\n",
    "    #bac = [x for x in seq_ids if seq_ids[x]==\"b\"]\n",
    "    #nei = [x for x in seq_ids if seq_ids[x]==\"n\"]\n",
    "    #mbn = [len(met),len(bac),len(nei)]\n",
    "    #print(\"%s -- metazoa:%i,bacteria:%i,other:%i\" %(cluster,len(met),len(bac),len(nei)))\n",
    "    for i in range(n):\n",
    "        trial_name = \"%s_%i\"%(cluster, i+1)\n",
    "        sample = random.choices(met, k=int(batch_size*(5/12))) + random.choices(bac, k=int(batch_size*(5/12))) + random.choices(nei, k=int(batch_size*(1/6)))\n",
    "        makeAlignment(trial_name, sample)\n",
    "    if full_tree:\n",
    "        makeAlignment(\"%s_full\"%(cluster), met+bac+nei)\n",
    "    if return_tax:\n",
    "        return seq_ids, seq_tax, mbn\n",
    "    else:\n",
    "        return seq_ids, seq_tax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_default_names(alignment_path, taxdict, groupdict):\n",
    "    old = fastaToDictionary(alignment_path)\n",
    "    #print([x for x in old])\n",
    "    oldsplit = {x.split()[0]:old[x] for x in old}\n",
    "    oldsplit = {x:oldsplit[x] for x in oldsplit}\n",
    "    new = {\"|\".join([groupdict[x], taxdict[x], x]):oldsplit[x] for x in oldsplit if x in groupdict}\n",
    "    #print(len(old), len(oldsplit), len(new))\n",
    "    with open(alignment_path.replace(\".afa\", \"_rn.afa\"), 'w') as out:\n",
    "        for seq in new:\n",
    "            out.write(\">\" + seq + \"\\n\" + new[seq] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer metazoan-bacterial distance\n",
    "\n",
    "def calculateMBDistance(tree):\n",
    "    tree = tree.copy()\n",
    "    mAndB = []\n",
    "    for leaf in tree.get_leaves():\n",
    "        #iqtree turns | into _\n",
    "        if \"|\" not in leaf.name:\n",
    "            parts = leaf.name.split(\"_\")\n",
    "            leaf.name = \"|\".join(parts[0:2] + [\"_\".join(parts[2:])])\n",
    "        if leaf.name[0] in ['m', 'b']:\n",
    "            mAndB.append(leaf)\n",
    "    tree.prune(mAndB, preserve_branch_length=True)\n",
    "\n",
    "    leaves = tree.get_leaves()\n",
    "    animalRoot = next(x for x in leaves if x.name[0] == 'm')\n",
    "    tree.set_outgroup(animalRoot)\n",
    "\n",
    "    # Label the easy ones (e.g. nodes with all bacterial or metazoan children)\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            clade = getClade(node)\n",
    "            node.add_feature(\"nodeName\", node.name.split('/')[0])\n",
    "            if node.is_root():\n",
    "                node.name = 'r'\n",
    "            elif clade:\n",
    "                node.name = clade\n",
    "\n",
    "    # Loops until all internal nodes are labelled\n",
    "    while not all(x.name in ['b', 'm', 'u', 'r'] or x.is_leaf() for x in tree.traverse()):\n",
    "        # Grabs all the already-labelled internal nodes\n",
    "        toLookAt = [x for x in tree.traverse() if \n",
    "                    (x.name in ['b', 'm', 'u']) or x.is_leaf()]\n",
    "        mut = []\n",
    "        for node in toLookAt:\n",
    "            par = node.up\n",
    "            # If the parent's already labelled, continue\n",
    "            if par.name in ['b', 'm', 'u', 'r']:\n",
    "                continue\n",
    "\n",
    "            # If the sister doesn't have a name, continue\n",
    "            sis = getSis(node)\n",
    "            if sis.is_leaf():\n",
    "                sisName = sis.name[0]\n",
    "            elif sis.name in ['b', 'm', 'u']:\n",
    "                sisName = sis.name\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if node.is_leaf():\n",
    "                nodeName = node.name[0]\n",
    "            else:\n",
    "                nodeName = node.name\n",
    "\n",
    "            # If the node and its sister have the same label, give the parent that label\n",
    "            if nodeName == sisName:\n",
    "                par.name = nodeName\n",
    "            # Use the parent's sister to infer parent's label, if node and sister\n",
    "            # have conflicting labels\n",
    "            else:\n",
    "                parSis = getSis(par)\n",
    "                if parSis.is_leaf():\n",
    "                    parSisName = parSis.name[0]\n",
    "                else:\n",
    "                    parSisName = parSis.name\n",
    "                # Hopefully parent's sister is labelled\n",
    "                if parSisName in ['b', 'm', 'u']:\n",
    "                    # If parent's sister matches one of the parent's children,\n",
    "                    # parent is assigned that label\n",
    "                    if parSisName in [nodeName, sisName]:\n",
    "                        par.name = parSisName\n",
    "                    # Propagate unknown (e.g ((M,B),U) or ((M,U),B))\n",
    "                    else:\n",
    "                        par.name = 'u'\n",
    "                # If parent's sister is unlabelled, either wait until it is,\n",
    "                # or recognize that neither can inform each other and label\n",
    "                # as unknown (e.g. ((M,B),(M,B)))\n",
    "                else:\n",
    "                    if [parSis,par] in mut:\n",
    "                        par.name = 'u'\n",
    "                        parSis.name = 'u'\n",
    "                    else:\n",
    "                        mut.append([par, parSis])\n",
    "\n",
    "    # Make the OG a bacterial subtree\n",
    "    for node in [x for x in tree.traverse() if x.name == \"b\"]:\n",
    "        if node.up.name == \"m\":\n",
    "            tree.set_outgroup(node)\n",
    "            break\n",
    "\n",
    "    tree.set_outgroup(animalRoot)\n",
    "    dists = []\n",
    "    for node in [x for x in tree.traverse() if not (x.is_root() or x.is_leaf())]:\n",
    "        par = node.up\n",
    "        if node.name == 'u' or par.name == 'u' or par.name == 'r':\n",
    "            continue\n",
    "        kidNames = [x.name.split('|')[1] for x in node.get_leaves()]\n",
    "        if len(list(set(kidNames))) == 1:\n",
    "            #print(node)\n",
    "            continue\n",
    "        if node.name != par.name:\n",
    "            dists.append(node.dist)\n",
    "            #print(node.dist)\n",
    "    if dists == []:\n",
    "        #print(\"Too uncertain\")\n",
    "        return []\n",
    "    else:\n",
    "        return dists\n",
    "    #else:\n",
    "    #    tree.write(format=1,outfile=\"uhOh2.tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer taxonomic coverage\n",
    "# A high ratio of unique genera to unique phyla implies vertical inheritance\n",
    "def inferTaxonomicCoverage(blastHitsFile, modifier=None, tid_in_lineage=None):\n",
    "    f = open(blastHitsFile)\n",
    "    flines = [line.strip() for line in f]\n",
    "    f.close()\n",
    "\n",
    "    all_taxa = {\"phylum\":set(), \"class\":set(), \"order\":set(), \"family\":set(), \"genus\":set()}\n",
    "    cluster_taxa = {}\n",
    "\n",
    "    seen = {}\n",
    "    count = 0\n",
    "    for line in flines:\n",
    "        if count % 1000 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(count, round(count/len(flines)*100,2), len(all_taxa[\"phylum\"]), len(all_taxa[\"genus\"]))\n",
    "        count += 1\n",
    "        seq, clust, tids, dom = line.split()\n",
    "        if (not (modifier is None)) and dom != modifier:\n",
    "            continue\n",
    "        tid = tids.split(',')[0]\n",
    "        if tid in seen:\n",
    "            lineage, ranks = seen[tid]\n",
    "            new = False\n",
    "        else:\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    lineage = ncbi.get_lineage(tid)\n",
    "            except:\n",
    "                print(\"Invalid taxid:\", tid)\n",
    "                seen[tid] = ([], {})\n",
    "                continue\n",
    "            if (not (tid_in_lineage is None)) and tid_in_lineage not in lineage: \n",
    "                lineage, ranks = [], {}\n",
    "            else:\n",
    "                ranks = ncbi.get_rank(lineage)\n",
    "                lineage = [x for x in lineage if ranks[x] in all_taxa]\n",
    "                ranks = {x:ranks[x] for x in ranks if x in lineage}\n",
    "            new = True\n",
    "            seen[tid] = (lineage, ranks)\n",
    "        for lin_tid in lineage:\n",
    "            rank = ranks[lin_tid]\n",
    "            clusts = clust.split(',')\n",
    "            for c in clusts:\n",
    "                if c not in cluster_taxa:\n",
    "                    cluster_taxa[c] = {\"phylum\":set(), \"class\":set(), \"order\":set(), \"family\":set(), \"genus\":set()}\n",
    "                #if lin_tid not in cluster_taxa[c][rank]:\n",
    "                cluster_taxa[c][rank].add(lin_tid)\n",
    "            if new: #and lin_tid not in all_taxa[rank]:\n",
    "                all_taxa[rank].add(lin_tid)\n",
    "                \n",
    "    all_taxa = {x:list(all_taxa[x]) for x in all_taxa}\n",
    "    for c in cluster_taxa:\n",
    "        cluster_taxa[c] = {x:list(cluster_taxa[c][x]) for x in cluster_taxa[c]}\n",
    "    return all_taxa, cluster_taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fastas(fastas, out_path):\n",
    "    out = open(out_path, 'w')\n",
    "    seen = []\n",
    "    stop = False\n",
    "    for fasta_path in fastas:\n",
    "        with open(fasta_path) as f:\n",
    "            for line in f.readlines():\n",
    "                l = line.strip()\n",
    "                if l and l[0]==\">\":\n",
    "                    if l in seen:\n",
    "                        stop = True\n",
    "                        continue\n",
    "                    stop = False\n",
    "                    seen.append(l)\n",
    "                if not stop:\n",
    "                    out.write(l+\"\\n\")\n",
    "    out.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all trees to single figtree NEXUS file for visualization\n",
    "def merge_and_write_trees(cluster, trees,out_path, sort_by=None, linDict={}, rankDict={}, nameDict={}, reuse=False):\n",
    "    #linDict = {}\n",
    "    #rankDict = {}\n",
    "    #nameDict = {}\n",
    "    favCutoff = \"40\"\n",
    "    taxLines = []\n",
    "    treeLines = []\n",
    "    #maxDists = {}\n",
    "    #for file in dists:\n",
    "    #    maxDists[file] = max(dists[file])\n",
    "    if sort_by:\n",
    "        sort_by_tuples = [(x,sort_by[x]) for x in sort_by]\n",
    "        sorted_trees = sorted(sort_by_tuples.items(), key=operator.itemgetter(1))\n",
    "        sorted_trees = [x[0] for x in sorted_trees]\n",
    "    else:\n",
    "        sorted_trees = trees\n",
    "    #out = open(\"trees/cluster\" + favCutoff + \"/geneNames.txt\", 'w')\n",
    "    #for file, dist in sorted_trees:\n",
    "    #    if file[0] == \"h\":\n",
    "    #        continue\n",
    "    #    out.write(file + \",\" + clustAnnotations[file] + \",\" + \" \".join([str(x) for x in dists[file]]) + \"\\n\")\n",
    "    #out.close()\n",
    "\n",
    "    for file in sorted_trees:\n",
    "        print(file)\n",
    "        #if file[0] == \"h\":\n",
    "        #    continue\n",
    "        tree = trees[file]\n",
    "        taxTree = tree.copy()\n",
    "        for node in taxTree.traverse():\n",
    "            if node.is_leaf():\n",
    "                parts = node.name.split('|')\n",
    "                taxid = int(parts[1].split(',')[0])\n",
    "                gen_spe = nameDict.get(taxid)\n",
    "                if gen_spe is None:\n",
    "                    try:\n",
    "                        gen_spe = ncbi.get_taxid_translator([taxid])[taxid]\n",
    "                    except:\n",
    "                        taxLine = '\\t%s [&gen_spe=\"%s\"]' %(node.name, \"idk\")\n",
    "                        taxLines.append(taxLine)\n",
    "                        continue\n",
    "                taxLine = '\\t%s [&gen_spe=\"%s\"' %(node.name, gen_spe)\n",
    "\n",
    "                lin = linDict.get(taxid)\n",
    "                if not lin:\n",
    "                    lin = ncbi.get_lineage(taxid)\n",
    "                    linDict[taxid] = lin\n",
    "                notIn = [x for x in lin if x not in nameDict]\n",
    "                names = ncbi.get_taxid_translator(notIn)\n",
    "                ranks = ncbi.get_rank(notIn)\n",
    "                for name in names:\n",
    "                    nameDict[name] = names[name]\n",
    "                    rankDict[name] = ranks[name]\n",
    "                lineage = dict([(rankDict[x], nameDict[x]) for x in lin])\n",
    "                for rank in ['phylum', 'class', 'order', 'family']:\n",
    "                    if rank in lineage:\n",
    "                        taxLine += ' tax_%s=\"%s\"' %(rank, lineage[rank])\n",
    "                if 2 in lin: #bacteria\n",
    "                    dom = \"bac\"\n",
    "                elif 2157 in lin: #archaea\n",
    "                    dom = \"arc\"\n",
    "                elif 2759 in lin: #eukaryota\n",
    "                    #if 33213 in lin:\n",
    "                    #    dom = \"bil\"\n",
    "                    if 33208 in lin: #metazoa\n",
    "                        dom = \"met\"\n",
    "                    elif 4751 in lin: #fungi\n",
    "                        dom = \"fun\"\n",
    "                    elif 33090 in lin: #viridiplantae\n",
    "                        dom = \"pla\"\n",
    "                    else:\n",
    "                        dom = \"euk\" \n",
    "                else: #other\n",
    "                    dom = \"nan\"\n",
    "                taxLine += ' group=\"%s\"' %(dom)\n",
    "                taxLine += ' fullTax=\"%s\"' %'_'.join([nameDict[x] for x in lin])\n",
    "                taxLine += ']'\n",
    "                taxLines.append(taxLine)\n",
    "                #print(dom)\n",
    "            else:\n",
    "                if node.name:\n",
    "                    if '/' in node.name:\n",
    "                        write_format = 1\n",
    "                        bits = node.name.split('/')\n",
    "                        aLRT, UFBoot = node.name.split('/')\n",
    "                        node.name = '[&nodeName=%s,UFBoot=%.2f,aLRT=%.2f]' %(node.name, float(UFBoot), float(aLRT))\n",
    "                    else:\n",
    "                        write_format = 0\n",
    "                        node.support = float(node.name)\n",
    "\n",
    "        newick_text = taxTree.write(format=write_format)\n",
    "        #print(newick_text)\n",
    "        if write_format>0:\n",
    "            regBit = '_&nodeName_(\\d+\\.?\\d?\\/\\d+)_UFBoot_(\\d+\\.\\d\\d)_aLRT_(\\d+\\.\\d\\d)_'\n",
    "            #regBit = '_&nodeName_(Node\\d+)_UFBoot_(\\d+\\.\\d\\d)_aLRT_(\\d+\\.\\d\\d)_AD_(\\d+\\.\\d+)_'\n",
    "            newLab = '[&nodeName=\\\\1,UFBoot=\\\\2,aLRT=\\\\3]'\n",
    "            #newLab = '[&nodeName=\\\\1,UFBoot=\\\\2,aLRT=\\\\3,AD=\\\\4]'\n",
    "            newick_text = re.sub(regBit, newLab, newick_text)\n",
    "        #print(newick_text)\n",
    "        treeLines.append(\"\\ttree %s = [&R] %s\" %(file, newick_text))\n",
    "\n",
    "    out = open(out_path, 'w')\n",
    "    out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(taxLines))\n",
    "    out.write('\\n'.join(taxLines))\n",
    "    out.write(';\\nend;\\n')\n",
    "    out.write('begin trees;\\n%s\\nend;' %'\\n'.join(treeLines))\n",
    "    out.write(\"begin figtree;\\n\\tset tipLabels.colorAttribute=\\\"group\\\";\")\n",
    "    out.write(\"\\n\\tset tipLabels.displayAttribute=\\\"tax_phylum\\\";\\nend;\")\n",
    "    out.close()\n",
    "    if reuse:\n",
    "        return linDict, rankDict, nameDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all_names(alignment_path):\n",
    "    alignments = [x for x in os.listdir(alignment_path) if \"afa\" == x.split(\".\")[-1] and os.path.getsize(alignment_path+x)>0]\n",
    "    aligned_clusters = list(set([\"_\".join(x.split(\"_\")[:2]) for x in alignments]))\n",
    "    for clust in aligned_clusters:\n",
    "        sub_aligns = [x for x in alignments if clust in x and \"_rn.afa\" not in x]\n",
    "        sub_aligns = [x for x in sub_aligns if x.replace(\".afa\",\"_rn.afa\") not in alignments]\n",
    "        if len(sub_aligns) == 0:\n",
    "            continue\n",
    "        groupdict, taxdict = generate_small_alignments(clust, blast_path, n=0, batch_size=0)\n",
    "        for file in sub_aligns:\n",
    "            print(\"Renaming\", file)\n",
    "            update_default_names(alignment_path+file, taxdict, groupdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_blast_by_domain(blast_path, unique=False, clusters_of_interest=None, write_path=False):\n",
    "    #cluster_counts = {}\n",
    "    cluster_groups = {}\n",
    "\n",
    "    seen = {}\n",
    "    tax_ids = {2157:\"a\", 33090:\"p\", 4751:\"f\"}\n",
    "    lines = []\n",
    "    with open(blast_path) as f:\n",
    "        for line in f:\n",
    "            parts = [x.strip() for x in line.split()]\n",
    "            dom = parts[3]\n",
    "            tid = parts[2]\n",
    "            tid = tid.split(\",\")[0]\n",
    "            clusters = parts[1].split(\",\")\n",
    "            for cluster in clusters:\n",
    "                if clusters_of_interest:\n",
    "                    if cluster not in clusters_of_interest:\n",
    "                        continue\n",
    "                if cluster not in cluster_groups:\n",
    "                    #cluster_counts[cluster] = {tax_ids[x]:0 for x in tax_ids}\n",
    "                    cluster_groups[cluster] = {tax_ids[x]:[] for x in tax_ids}\n",
    "                if dom not in cluster_groups[cluster]:\n",
    "                    #cluster_counts[cluster][dom] = 0\n",
    "                    cluster_groups[cluster][dom] = []\n",
    "                #cluster_counts[cluster][dom] += 1\n",
    "                cluster_groups[cluster][dom].append(tid)\n",
    "                if dom == \"n\":\n",
    "                    if tid in seen:\n",
    "                        lin = seen[tid]\n",
    "                    else:\n",
    "                        try:\n",
    "                            lin = ncbi.get_lineage(tid)\n",
    "                        except:\n",
    "                            lin = []\n",
    "                        seen[tid] = lin\n",
    "                    for tax_id in tax_ids:\n",
    "                        if tax_id in lin:\n",
    "                            dom = tax_ids[tax_id]\n",
    "                            #cluster_counts[cluster][dom] += 1\n",
    "                            cluster_groups[cluster][dom].append(tid)\n",
    "            if write_path:\n",
    "                parts[3] = dom\n",
    "                lines.append(\"\\t\".join(parts))\n",
    "    if write_path:\n",
    "        out = open(write_path, 'w')\n",
    "        out.write(\"\\n\".join(lines))\n",
    "        out.close()\n",
    "    cluster_counts = {}\n",
    "    for cluster in cluster_groups:\n",
    "        if unique:\n",
    "            cluster_groups[cluster] = {x:list(set(cluster_groups[cluster][x])) for x in cluster_groups[cluster]}\n",
    "        cluster_counts[cluster] = {x:len(cluster_groups[cluster][x]) for x in cluster_groups[cluster]}\n",
    "    return cluster_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_range(values, exclude_outliers=False):\n",
    "    if exclude_outliers:\n",
    "        q75, q25 = np.percentile(values, [75 ,25])\n",
    "        iqr = q75 - q25\n",
    "        too_high = [x for x in values if x>(q75+(1.5*iqr))]\n",
    "        too_low = [x for x in values if x<(q25-(1.5*iqr))]\n",
    "        #print(values, too_high, too_low)\n",
    "        values = [x for x in values if x not in too_high+too_low]\n",
    "    return max(values) - min(values)\n",
    "\n",
    "def calc_iqr(values):\n",
    "    q75, q25 = np.percentile(values, [75 ,25])\n",
    "    return q75 - q25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_with_separators_to_count_dict(list_with_separators, separator=\",\"):\n",
    "    out = {}\n",
    "    for item in list_with_separators:\n",
    "        for sub_item in item.split(separator):\n",
    "            if sub_item in out:\n",
    "                out[sub_item]+=1\n",
    "            else:\n",
    "                out[sub_item]=1\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
